{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "13PDAPpKdoY7wwyH0JP79b_qxs4nT5QG7",
      "authorship_tag": "ABX9TyOtSlwhoMjwAl2kStCVjpfE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzens/myOriginalRzens/blob/master/HowToUseCuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 连接到 google 云盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/Dataset/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql5ChshdiD-I",
        "outputId": "25f66c2b-5a8b-4a05-e1ef-3cb79e936c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Dataset\n",
            "/content/drive/MyDrive/Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud8FkyKrg1Lo"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Flatten, Linear\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# from TrainModel import Model\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"drive/MyDrive/Dataset\", train=True, transform=torchvision.transforms.ToTensor(),\n",
        "                                          download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"drive/MyDrive/Dataset\", train=False, transform=torchvision.transforms.ToTensor(),\n",
        "                                         download=True)\n",
        "\n",
        "train_data_size = len(train_data)\n",
        "print(\"训练数据集的长度为：{}\".format(train_data_size))\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=256)\n",
        "test_dataloader = DataLoader(test_data, batch_size=256)\n",
        "\n",
        "\n",
        "# 搭建神经网络\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.model1 = Sequential(\n",
        "            Conv2d(3, 32, 5, padding=2),\n",
        "            MaxPool2d(2),\n",
        "            Conv2d(32, 32, 5, padding=2),\n",
        "            MaxPool2d(2),\n",
        "            Conv2d(32, 64, 5, padding=2),\n",
        "            MaxPool2d(2),\n",
        "            Flatten(),\n",
        "            Linear(1024, 64),\n",
        "            Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# 定义训练的设备\n",
        "if torch.cuda.is_available():\n",
        "    print(\"use cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda\")\n",
        "# device = torch.device(\"cuda:0\")\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "loss_tm = CrossEntropyLoss()\n",
        "loss_tm = loss_tm.to(device)\n",
        "learning_rate = 0.001\n",
        "optim_tm = SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_train_steps = 0\n",
        "total_test_steps = 0\n",
        "epoch = 100  # 模型将对一个数据集学习 epoch 次\n",
        "\n",
        "writer = SummaryWriter(\"Train\")\n",
        "test_data_size = len(test_data)  # 查看总的测试集数据量大小，便于求正确率\n",
        "for i in range(epoch):\n",
        "    print()\n",
        "    start_time = time.time()\n",
        "    print(\"第 {} 轮训练开始\".format(i))\n",
        "    model.train()  # 将模型设置为 train 模式，dropout 和 bn 等正常使用\n",
        "    for data in train_dataloader:\n",
        "        imgs, targets = data\n",
        "        imgs = imgs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        ys = model(imgs)\n",
        "        loss = loss_tm(ys, targets)\n",
        "\n",
        "        optim = optim_tm.zero_grad()\n",
        "        loss.backward()\n",
        "        optim_tm.step()\n",
        "\n",
        "        writer.add_scalar(\"train_loss\", loss.item(), total_train_steps)\n",
        "        total_train_steps += 1\n",
        "\n",
        "    # 当完成一轮训练时，正常流程是进行模型学习能力的验证\n",
        "    model.eval()  # 将模型设置为 eval 模式，dropout 和 bn 等被禁用掉\n",
        "    total_test_loss = 0\n",
        "    total_accurate = 0  # 一次 epoch 后对模型的验证的正确个数\n",
        "    with torch.no_grad():\n",
        "        for data in test_dataloader:\n",
        "            imgs, targets = data\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_tm(outputs, targets)\n",
        "            total_test_loss += loss.item()\n",
        "            batch_accurate = (\n",
        "                        outputs.argmax(1) == targets).sum()  # 看 True 的个数有多少，即预测出的 index 和 正确的 targets 中 index 是否相等\n",
        "            # print(\"本 batch 正确个数：\", batch_accurate.item())\n",
        "            total_accurate += batch_accurate.item()  # 积累每次测试新数据的准确度\n",
        "    print(\"验证集损失：{}。\".format(total_test_loss))\n",
        "    print(\"本次 epoch 正确率：{}。\".format(total_accurate / test_data_size))\n",
        "    writer.add_scalar(\"test_loss\", total_test_loss, total_train_steps)\n",
        "    writer.add_scalar(\"accuracy\", total_accurate / test_data_size, total_train_steps)\n",
        "    total_test_steps += 1\n",
        "    end_time = time.time()\n",
        "    print(\"本 epoch 运行时间：\", end_time - start_time)  # 输出是以 s 为单位\n",
        "writer.close()\n",
        "torch.save(model.state_dict(), \"model.pth\")  # 保存参数\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Flatten, Linear\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# from TrainModel import Model\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"drive/MyDrive/Dataset\", train=True,\n",
        "                                          transform=torchvision.transforms.ToTensor(),\n",
        "                                          download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"drive/MyDrive/Dataset\", train=False,\n",
        "                                         transform=torchvision.transforms.ToTensor(),\n",
        "                                         download=True)\n",
        "\n",
        "train_data_size = len(train_data)\n",
        "print(\"训练数据集的长度为：{}\".format(train_data_size))\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=256)\n",
        "test_dataloader = DataLoader(test_data, batch_size=256)\n",
        "\n",
        "\n",
        "# 搭建神经网络\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.model1 = Sequential(\n",
        "            Conv2d(3, 32, 5, padding=2),\n",
        "            MaxPool2d(2),\n",
        "            Conv2d(32, 32, 5, padding=2),\n",
        "            MaxPool2d(2),\n",
        "            Conv2d(32, 64, 5, padding=2),\n",
        "            MaxPool2d(2),\n",
        "            Flatten(),\n",
        "            Linear(1024, 64),\n",
        "            Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# 定义训练的设备\n",
        "if torch.cuda.is_available():\n",
        "    print(\"use cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ##### directml ##### #\n",
        "# import torch_directml\n",
        "# print(\"torch_directml\")\n",
        "# device = torch_directml.device()\n",
        "# ##### directml ##### #\n",
        "\n",
        "# device = torch.device(\"cuda\")\n",
        "# device = torch.device(\"cuda:0\")\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "loss_tm = CrossEntropyLoss()\n",
        "loss_tm = loss_tm.to(device)\n",
        "learning_rate = 0.01\n",
        "optim_tm = Adam(model.parameters())\n",
        "\n",
        "# ##### intel ##### #\n",
        "# import intel_extension_for_pytorch as ipex\n",
        "# model, optim_tm = ipex.optimize(model, optimizer=optim_tm)\n",
        "#\n",
        "\n",
        "\n",
        "total_train_steps = 0\n",
        "total_test_steps = 0\n",
        "epoch = 70  # 模型将对一个数据集学习 epoch 次\n",
        "\n",
        "writer = SummaryWriter(\"Train\")\n",
        "test_data_size = len(test_data)  # 查看总的测试集数据量大小，便于求正确率\n",
        "for i in range(epoch):\n",
        "    print()\n",
        "    start_time = time.time()\n",
        "    print(\"第 {} 轮训练开始\".format(i))\n",
        "    model.train()  # 将模型设置为 train 模式，dropout 和 bn 等正常使用\n",
        "    for data in train_dataloader:\n",
        "        imgs, targets = data\n",
        "        imgs = imgs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        ys = model(imgs)\n",
        "        loss = loss_tm(ys, targets)\n",
        "\n",
        "        optim = optim_tm.zero_grad()\n",
        "        loss.backward()\n",
        "        optim_tm.step()\n",
        "\n",
        "        writer.add_scalar(\"train_loss\", loss.item(), total_train_steps)\n",
        "        total_train_steps += 1\n",
        "\n",
        "    # 当完成一轮训练时，正常流程是进行模型学习能力的验证\n",
        "    model.eval()  # 将模型设置为 eval 模式，dropout 和 bn 等被禁用掉\n",
        "    total_test_loss = 0\n",
        "    total_accurate = 0  # 一次 epoch 后对模型的验证的正确个数\n",
        "    with torch.no_grad():\n",
        "        for data in test_dataloader:\n",
        "            imgs, targets = data\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_tm(outputs, targets)\n",
        "            total_test_loss += loss.item()\n",
        "            batch_accurate = (\n",
        "                    outputs.argmax(1) == targets).sum()  # 看 True 的个数有多少，即预测出的 index 和 正确的 targets 中 index 是否相等\n",
        "            # print(\"本 batch 正确个数：\", batch_accurate.item())\n",
        "            total_accurate += batch_accurate.item()  # 积累每次测试新数据的准确度\n",
        "    print(\"验证集损失：{}。\".format(total_test_loss))\n",
        "    print(\"本次 epoch 正确率：{}。\".format(total_accurate / test_data_size))\n",
        "    writer.add_scalar(\"test_loss\", total_test_loss, total_train_steps)\n",
        "    writer.add_scalar(\"accuracy\", total_accurate / test_data_size, total_train_steps)\n",
        "    total_test_steps += 1\n",
        "    end_time = time.time()\n",
        "    print(\"本 epoch 运行时间：\", end_time - start_time)  # 输出是以 s 为单位\n",
        "writer.close()\n",
        "torch.save(model.state_dict(), \"model.pth\")  # 保存参数"
      ],
      "metadata": {
        "id": "t_mznzLbiF9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 通用的训练流程\n",
        "# 以及看各个类的准确度\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.nn import Linear, CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 获取数据\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"drive/MyDrive/Dataset\", train=True,\n",
        "                                          transform=torchvision.transforms.ToTensor(),\n",
        "                                          download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"drive/MyDrive/Dataset\", train=False,\n",
        "                                         transform=torchvision.transforms.ToTensor(),\n",
        "                                         download=True)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=256)\n",
        "test_dataloader = DataLoader(test_data, batch_size=256)\n",
        "# 定义模型\n",
        "vgg16 = torchvision.models.vgg16(pretrained=False)  # pretrained=False - 模型的参数是随机的，没有经过训练\n",
        "\n",
        "# 如果是引入预训练的模型，则需要再下载这个模型的参数。下载操作是自动的\n",
        "# vgg16_true = torchvision.models.vgg16(pretrained=True)  # pretrained=True - 模型的参数是已经经过预先训练了\n",
        "\n",
        "\n",
        "vgg16.classifier[6] = Linear(4096, 10)\n",
        "print(vgg16)  # 查看具体的模型结构\n",
        "\n",
        "# 定义训练的设备\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"use cuda\")\n",
        "\n",
        "vgg16.to(device)\n",
        "ce_loss = CrossEntropyLoss()\n",
        "ce_loss.to(device)\n",
        "adam_optim = Adam(vgg16.parameters())\n",
        "\n",
        "\n",
        "# ##### intel ##### #\n",
        "# import intel_extension_for_pytorch as ipex\n",
        "\n",
        "# vgg16, adam_optim = ipex.optimize(vgg16, optimizer=adam_optim)\n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "\n",
        "def train_model_a_epoch(model: torch.nn.Module, loss, optim: torch.optim.Optimizer, dataloader):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    for data in dataloader:\n",
        "        imgs, targets = data\n",
        "        imgs = imgs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        train_output = model(imgs)\n",
        "        train_loss = loss(train_output, targets)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optim.step()\n",
        "    end_time = time.time()\n",
        "    print(\"耗费时间 {}s\".format(end_time - start_time))\n",
        "\n",
        "\n",
        "def test_model_a_epoch(model: torch.nn.Module, loss, dataloader):\n",
        "    start_time = time.time()\n",
        "    test_data_size = len(dataloader)\n",
        "    total_test_loss = 0\n",
        "    total_test_accuracy = 0\n",
        "    total_test_classes_accuracy = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    total_test_classes_sum = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            imgs, targets = batch\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(imgs)\n",
        "            test_loss = loss(outputs, targets)\n",
        "            total_test_loss += test_loss.item()\n",
        "\n",
        "            \"\"\"\n",
        "            output 是一个至少 shape 是 A = [ B1 = [], B2 = [], ...]\n",
        "            .argmax(1) 将得到 B1 中最大值的那个 index\n",
        "            \"\"\"\n",
        "            batch_accuracy = (outputs.argmax(1) == targets).sum()\n",
        "            # 查看各类的准确度\n",
        "            for i in range(len(outputs.argmax(1))):\n",
        "                total_test_classes_sum[targets[i]] += 1\n",
        "                if outputs.argmax(1)[i] == targets[i]:\n",
        "                    total_test_classes_accuracy[targets[i]] += 1\n",
        "\n",
        "            total_test_accuracy += batch_accuracy.item()\n",
        "    print(\"验证集损失：{}。\".format(total_test_loss))\n",
        "    print(\"本次 epoch 正确率：{}。\".format(total_test_accuracy / test_data_size))\n",
        "    for i in range(len(total_test_classes_accuracy)):\n",
        "        if total_test_classes_sum[i] == 0:\n",
        "            continue\n",
        "        print(\"本次 epoch 中第\" + str(i) + \"个类别的正确率：\" +\n",
        "              str(total_test_classes_accuracy[i] / total_test_classes_sum[i]) + \"。\")\n",
        "        print(\"total_test_classes_accuracy\",total_test_classes_accuracy[i],\"total_test_classes_sum[i]\",total_test_classes_sum[i])\n",
        "    end_time = time.time()\n",
        "    print(\"耗费时间 {}s\".format(end_time - start_time))\n",
        "\n",
        "\n",
        "# 进行模型的训练\n",
        "if __name__ == \"__main__\":\n",
        "    total_epochs = 30\n",
        "    now_epoch = 0\n",
        "    for i in range(total_epochs):\n",
        "        print(\"第 {} 次训练开始\".format(now_epoch))\n",
        "        train_model_a_epoch(vgg16, ce_loss, adam_optim, train_dataloader)\n",
        "        print(\"第 {} 次测试开始\".format(now_epoch))\n",
        "        test_model_a_epoch(vgg16, ce_loss, test_dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Je8_VAMGom6e",
        "outputId": "ca88e1fb-b1f2-41ec-c2a0-705f3ea61006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "use cuda\n",
            "第 0 次训练开始\n",
            "耗费时间 39.83448123931885s\n",
            "第 0 次测试开始\n",
            "验证集损失：92.10527276992798。\n",
            "本次 epoch 正确率：25.0。\n",
            "本次 epoch 中第0个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第1个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第2个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第3个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第4个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第5个类别的正确率：1.0。\n",
            "total_test_classes_accuracy 1000 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第6个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第7个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第8个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第9个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "耗费时间 3.78918719291687s\n",
            "第 0 次训练开始\n",
            "耗费时间 33.06133484840393s\n",
            "第 0 次测试开始\n",
            "验证集损失：92.10422825813293。\n",
            "本次 epoch 正确率：25.0。\n",
            "本次 epoch 中第0个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第1个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第2个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第3个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第4个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第5个类别的正确率：1.0。\n",
            "total_test_classes_accuracy 1000 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第6个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第7个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第8个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第9个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "耗费时间 4.545353412628174s\n",
            "第 0 次训练开始\n",
            "耗费时间 32.81745982170105s\n",
            "第 0 次测试开始\n",
            "验证集损失：92.10439372062683。\n",
            "本次 epoch 正确率：25.0。\n",
            "本次 epoch 中第0个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第1个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第2个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第3个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第4个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第5个类别的正确率：1.0。\n",
            "total_test_classes_accuracy 1000 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第6个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第7个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第8个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第9个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "耗费时间 4.281469821929932s\n",
            "第 0 次训练开始\n",
            "耗费时间 33.01079964637756s\n",
            "第 0 次测试开始\n",
            "验证集损失：92.10421371459961。\n",
            "本次 epoch 正确率：25.0。\n",
            "本次 epoch 中第0个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第1个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第2个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第3个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第4个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第5个类别的正确率：1.0。\n",
            "total_test_classes_accuracy 1000 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第6个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第7个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第8个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "本次 epoch 中第9个类别的正确率：0.0。\n",
            "total_test_classes_accuracy 0 total_test_classes_sum[i] 1000\n",
            "耗费时间 3.8790011405944824s\n",
            "第 0 次训练开始\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e624b345ab4b>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第 {} 次训练开始\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mtrain_model_a_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第 {} 次测试开始\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mtest_model_a_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-e624b345ab4b>\u001b[0m in \u001b[0;36mtrain_model_a_epoch\u001b[0;34m(model, loss, optim, dataloader)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtrain_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}